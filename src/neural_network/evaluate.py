from ultralytics import YOLO
import json
import os
import shutil
import pandas as pd
from pathlib import Path

def evaluate():
    # --- CONFIGURARE ---
    # CautÄƒ automat cel mai nou model
    MODELS_DIR = Path('models')
    RESULTS_DIR = Path('results')
    DOCS_DIR = Path('docs')
    DATA_YAML = 'data/data.yaml'
    
    RESULTS_DIR.mkdir(exist_ok=True)
    DOCS_DIR.mkdir(exist_ok=True)

    # 1. GÄƒseÈ™te modelul
    all_models = list(MODELS_DIR.rglob("best.pt"))
    if not all_models:
        print("âŒ EROARE: Nu am gÄƒsit modelul antrenat!")
        return
    best_model_path = max(all_models, key=os.path.getmtime)
    print(f"ğŸš€ EvaluÄƒm modelul: {best_model_path}")
    
    # 2. CopiazÄƒ training_history.csv (din folderul de antrenare Ã®n results/)
    # YOLO salveazÄƒ un results.csv Ã®n folderul run-ului
    train_run_dir = best_model_path.parent.parent # models/drone_landing_lvl2
    yolo_csv = train_run_dir / "results.csv"
    
    if yolo_csv.exists():
        shutil.copy(yolo_csv, RESULTS_DIR / "training_history.csv")
        print("âœ… Istoric antrenare copiat Ã®n results/training_history.csv")
        
        # Copiem È™i Loss Curve pentru documentaÈ›ie
        yolo_png = train_run_dir / "results.png"
        if yolo_png.exists():
            shutil.copy(yolo_png, DOCS_DIR / "loss_curve.png")
            print("âœ… Loss Curve copiatÄƒ Ã®n docs/loss_curve.png")
    else:
        print("âš ï¸ Nu am gÄƒsit results.csv original.")

    # 3. RuleazÄƒ Evaluarea pe TEST SET
    print("ğŸ“Š RulÄƒm inferenÈ›a pe setul de TEST...")
    model = YOLO(best_model_path)
    metrics = model.val(
        data=DATA_YAML,
        split='test',       # Critic: EvaluÄƒm pe TEST, nu VALID
        imgsz=640,
        batch=8,
        device=0,
        plots=True,
        project='results',
        name='eval_run'
    )

    # 4. GenereazÄƒ test_metrics.json
    final_metrics = {
        "test_metrics": {
            "mask": {
                "map_50": round(metrics.seg.map50, 4),
                "map_50_95": round(metrics.seg.map, 4),
                "precision": round(metrics.seg.mp, 4),
                "recall": round(metrics.seg.mr, 4),
                # CalculÄƒm F1 manual
                "f1_score": round(2 * (metrics.seg.mp * metrics.seg.mr) / (metrics.seg.mp + metrics.seg.mr + 1e-16), 4)
            },
            "box": {
                "map_50": round(metrics.box.map50, 4),
                "map_50_95": round(metrics.box.map, 4)
            }
        },
        "model_used": str(best_model_path)
    }

    with open(RESULTS_DIR / 'test_metrics.json', 'w') as f:
        json.dump(final_metrics, f, indent=2)
    print("âœ… Metrici finale salvate Ã®n results/test_metrics.json")

    # 5. CopiazÄƒ Matricea de Confuzie
    eval_dir = RESULTS_DIR / 'eval_run'
    conf_matrix = list(eval_dir.glob("confusion_matrix*.png"))
    if conf_matrix:
        shutil.copy(conf_matrix[0], DOCS_DIR / "confusion_matrix.png")
        print("âœ… Matricea de confuzie salvatÄƒ Ã®n docs/")

    print("\nğŸ Proces de evaluare complet!")

if __name__ == "__main__":
    evaluate()